{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "824f4e3d-e868-410b-b152-e41bd1e8e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "083c7cd3-6da0-47d1-af7e-328a681d258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'awsome product. I love it'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc5717da-5c29-489b-81c6-3a8b8d2cc523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text =text.replace(punctuation, '')\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8a62196-34f5-4ef6-a898-b607a8403fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('../static/model/corpora/stopwords/english', 'r') as file:\n",
    "    sw=file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b82a6a7f-0c01-44ee-a00b-ebecc82c5e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cca4a8b7-4015-4edd-ac6b-387368974a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    data = pd.DataFrame([text], columns=['tweet'])\n",
    "    data['tweet']=data['tweet'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    data['tweet']=data['tweet'].apply(lambda x: \" \".join(re.sub(r'^https?:\\/\\/.*[\\r\\n]*','', x,flags=re.MULTILINE) for x in x.split()))\n",
    "    data[\"tweet\"]=data[\"tweet\"].str.replace('/d+','', regex=True)\n",
    "    data[\"tweet\"]=data[\"tweet\"].str.replace('/d+','', regex=True)\n",
    "    data[\"tweet\"]= data[\"tweet\"].apply(lambda x: \" \".join(x for x in x.split() if x not in sw))\n",
    "    data[\"tweet\"]=data[\"tweet\"].apply(lambda x: \" \".join(ps.stem(x) for x in x.split()))\n",
    "    return data[\"tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a18de22d-7626-4bb2-a29f-671523ce0756",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cleaned = preprocessing(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c1603e4-2f68-4eb9-903c-89bfdd273868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    awsom product. love\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff000f3e-f292-4272-a2e2-3ac96013755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('../static/model/vocabulary.txt', 'r') as vocabulary_file:\n",
    "    vocabulary_text = vocabulary_file.read().splitlines()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4409d807-3b83-49ae-8e5a-d930523b8d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1192"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb6ec85d-0505-401c-8a87-81714e886465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorizer(ds, vocabulary):\n",
    "    vectorizer_list = []\n",
    "    vocab_set = set(vocabulary)  # Use a set for faster lookup\n",
    "    \n",
    "    for sentence in ds:\n",
    "        sentence_list = np.zeros(len(vocabulary), dtype=np.float16)  # Use np.float16 to reduce memory usage\n",
    "        sentence_words = set(sentence.split())  # Split and convert sentence to a set to speed up membership checking\n",
    "        \n",
    "        for i, word in enumerate(vocabulary):\n",
    "            if word in sentence_words:  # Check if word exists in the sentence\n",
    "                sentence_list[i] = 1\n",
    "                \n",
    "        vectorizer_list.append(sentence_list)\n",
    "    \n",
    "    # Convert the list to a numpy array only once\n",
    "    vectorizer_list_new = np.asarray(vectorizer_list, dtype=np.float16)\n",
    "    \n",
    "    return vectorizer_list_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4243ffc6-acfb-4c28-b949-ba14ded8f2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_test_data = vectorizer(text_cleaned,vocabulary_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c523af3-f96e-49ac-bea0-20253427fc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c6d146d-715c-4212-8e7c-256ddf8b4aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open ('../static/model/model.pkl', 'rb') as f:\n",
    "    model1 = pickle.load(f)\n",
    "    model1.predict(vectorized_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5e0d414-d5d0-4083-be40-1c55dfba1450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "predictions=  model1.predict(vectorized_test_data)\n",
    "if predictions[0]==0:\n",
    "    print(\"Positive\")\n",
    "else:\n",
    "    print(\"Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb14d21-3144-4706-94ce-56b6f239a893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
